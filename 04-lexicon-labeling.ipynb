{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7-NOXNO5xLKK"
   },
   "source": [
    "# **Lexicon Labeling**\n",
    "\n",
    "Â© Kuncahyo Setyo Nugroho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4485,
     "status": "ok",
     "timestamp": 1656520062975,
     "user": {
      "displayName": "Kuncahyo Setyo Nugroho",
      "userId": "17903335045350097388"
     },
     "user_tz": -420
    },
    "id": "mJ9tDAkZ0wzD",
    "outputId": "b8d0b19d-accf-410c-b598-3c1ca7060b56"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from textblob import TextBlob\n",
    "from collections import Counter\n",
    "from json import load\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer # for multi-label binarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q1n0jgE-1f1J"
   },
   "outputs": [],
   "source": [
    "def __build_word_affect__(self):\n",
    "    affect_list = []\n",
    "    affect_dict = dict()\n",
    "    affect_frequencies = Counter()\n",
    "    lexicon_keys = self.__lexicon__.keys()\n",
    "\n",
    "    for word in self.words:\n",
    "        if word in lexicon_keys:\n",
    "            affect_list.extend(self.__lexicon__[word])\n",
    "            affect_dict.update({word: self.__lexicon__[word]})\n",
    "\n",
    "    for word in affect_list:\n",
    "        affect_frequencies[word] += 1\n",
    "    sum_values = sum(affect_frequencies.values())\n",
    "\n",
    "    affect_percent = {'fear': 0.0, 'anger': 0.0, 'surprise': 0.0, 'sadness': 0.0, 'disgust': 0.0, 'joy': 0.0}\n",
    "\n",
    "    for key in affect_frequencies.keys():\n",
    "        affect_percent.update({key: float(affect_frequencies[key]) / float(sum_values)})\n",
    "\n",
    "    self.affect_list = affect_list\n",
    "    self.affect_dict = affect_dict\n",
    "    self.raw_emotion_scores = dict(affect_frequencies)\n",
    "    self.affect_frequencies = affect_percent\n",
    "\n",
    "def top_emotions(self):\n",
    "    emo_dict = self.affect_frequencies\n",
    "    max_value = max(emo_dict.values())\n",
    "    top_emotions = []\n",
    "\n",
    "    for key in emo_dict.keys():\n",
    "        if emo_dict[key] == max_value:\n",
    "            top_emotions.append((key, max_value))\n",
    "\n",
    "    self.top_emotions = top_emotions\n",
    "\n",
    "def emotions_value(self):\n",
    "    emo_dict = self.affect_frequencies\n",
    "    max_value = max(emo_dict.values())\n",
    "    emotions_value = []\n",
    "\n",
    "    for key in emo_dict.keys():\n",
    "        if emo_dict[key] > 0.0:\n",
    "            emotions_value.append((key))\n",
    "            \n",
    "    self.emotions_value = emotions_value\n",
    "\n",
    "class NRCLex:\n",
    "    \"\"\"\n",
    "    Lexicon source is (C) 2016 National Research Council Canada (NRC) and library is for research purposes only.  \n",
    "    Source: http://sentiment.nrc.ca/lexicons-for-research/\n",
    "    \"\"\"\n",
    "    def __init__(self, lexicon_file='nrc_id.json'):\n",
    "        with open(lexicon_file, 'r') as json_file:\n",
    "            self.__lexicon__ = load(json_file)\n",
    "\n",
    "    def load_raw_text(self, text):\n",
    "        self.text = text.lower()\n",
    "        blob = TextBlob(self.text)\n",
    "        self.words = [w for w in blob.words]\n",
    "        self.sentences = list(blob.sentences)\n",
    "        __build_word_affect__(self)\n",
    "        top_emotions(self)\n",
    "        emotions_value(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wULVoDYu2MYn"
   },
   "outputs": [],
   "source": [
    "# create function to get the top emotions\n",
    "def lex_label(text):\n",
    "  nrc_emotion = NRCLex(lexicon_file='nrc_id.json')\n",
    "  nrc_emotion.load_raw_text(text)\n",
    "  return nrc_emotion.emotions_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22916,
     "status": "ok",
     "timestamp": 1656520319480,
     "user": {
      "displayName": "Kuncahyo Setyo Nugroho",
      "userId": "17903335045350097388"
     },
     "user_tz": -420
    },
    "id": "SZJoGQC52zlF",
    "outputId": "80786b8d-7f48-464c-e3b8-a405a562fe23"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "source_folder_path = 'data/data-for-annotation'\n",
    "destination_folder_path = 'data/result-lexicon-annotation'\n",
    "\n",
    "emotion_list = ['anger', 'disgust', 'fear', 'joy', 'sadness', 'surprise']\n",
    "\n",
    "for emotion in emotion_list:\n",
    "    df = pd.read_csv(f'{source_folder_path}/{emotion}.csv', usecols=['tweet'], encoding='utf8')\n",
    "    df['emotion'] = df['tweet'].apply(lex_label)\n",
    "    df.to_csv(f'{destination_folder_path}/{emotion}.csv')\n",
    "\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    binarizer_df = df.join(pd.DataFrame(mlb.fit_transform(df.pop('emotion')), columns=mlb.classes_, index=df.index))\n",
    "    binarizer_df.to_csv(f'{destination_folder_path}/binarizer/{emotion}.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOJMIb2+/CsTDoHWl4cpHoR",
   "collapsed_sections": [],
   "name": "04-lexicon-labeling.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
